{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition : [Homesite Quote Conversion](https://www.kaggle.com/quantify/homesite-quote-conversion)\n",
    "\n",
    "![](https://kaggle2.blob.core.windows.net/competitions/kaggle/4657/logos/front_page.png)\n",
    "\n",
    "## Which customers will purchase a quoted insurance plan?\n",
    "\n",
    "Before asking someone on a date or skydiving, it's important to know your likelihood of success. The same goes for quoting home insurance prices to a potential customer. Homesite, a leading provider of homeowners insurance, does not currently have a dynamic conversion rate model that can give them confidence a quoted price will lead to a purchase. \n",
    "\n",
    "Using an anonymized database of information on customer and sales activity, including property and coverage information, Homesite is challenging you to predict which customers will purchase a given quote. Accurately predicting conversion would help Homesite better understand the impact of proposed pricing changes and maintain an ideal portfolio of customer segments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This dataset represents the activity of a large number of customers who are interested in buying policies from Homesite. Each QuoteNumber corresponds to a potential customer and the QuoteConversion_Flag indicates whether the customer purchased a policy.\n",
    "\n",
    "The provided features are anonymized and provide a rich representation of the prospective customer and policy. They include specific coverage information, sales information, personal information, property information, and geographic information. Your task is to predict QuoteConversion_Flag for each QuoteNumber in the test set.\n",
    "\n",
    "### File descriptions\n",
    "\n",
    "- train.csv - the training set, contains QuoteConversion_Flag\n",
    "- test.csv - the test set, does not contain QuoteConversion_Flag\n",
    "- sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days left: 34\n"
     ]
    }
   ],
   "source": [
    "#Deadline: 1st Febuary, 2016\n",
    "    \n",
    "from datetime import date\n",
    "print \"Number of days left: \" + str(abs((date.today() - date(2016, 02, 01)).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('data/input/train.csv', sep=',', header=0, quoting=2, skip_blank_lines=True)\n",
    "test_data = pd.read_csv('data/input/test.csv', sep=',')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print pd.value_counts(train_data.QuoteConversion_Flag)*100/len(train_data.QuoteConversion_Flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = train_data.QuoteConversion_Flag\n",
    "test_ind = test_data.QuoteNumber\n",
    "\n",
    "def pre_processing(data):\n",
    "    # Extract month and date part\n",
    "    data['Date'] = pd.to_datetime(pd.Series(data['Original_Quote_Date']))\n",
    "    # Now drop this column from the data frame\n",
    "    data = data.drop('Original_Quote_Date', axis=1)\n",
    "    data['year'] = data['Date'].apply(lambda x: int(str(x)[0:4]))\n",
    "    data['month'] = data['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "    data['day'] = data['Date'].apply(lambda x: int(str(x)[8:10]))\n",
    "    data['weekday'] = data['Date'].dt.dayofweek\n",
    "    data.drop('Date', axis=1, inplace=True)\n",
    "        \n",
    "    \"\"\"        \n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for f in data.columns:\n",
    "        if data[f].dtype=='object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(data[f].values))\n",
    "            data[f] = lbl.transform(list(data[f].values))\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = pre_processing(train_data)\n",
    "test_data = pre_processing(test_data)\n",
    "\n",
    "\n",
    "train_data.drop(['QuoteNumber','QuoteConversion_Flag'], axis=1, inplace=True)\n",
    "test_data.drop('QuoteNumber', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "train = train_data.T.to_dict().values()\n",
    "test = test_data.T.to_dict().values()\n",
    "\n",
    "#Transfer the list of dictionaries into a sparse matrix\n",
    "vec = DictVectorizer()\n",
    "train = vec.fit_transform(train)\n",
    "test = vec.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"silent\"] = 1\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"eval_metric\"] = \"auc\"\n",
    "params[\"booster\"] = \"gbtree\"\n",
    "params[\"eta\"] = 0.01\n",
    "params[\"min_child_weight\"] = 3\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.8\n",
    "params[\"nthread\"] = 4\n",
    "#params[\"scale_pos_weight\"] = 1\n",
    "\n",
    "plst = list(params.items())\n",
    "offset = 10000\n",
    "\n",
    "num_rounds = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgtest = xgb.DMatrix(test)\n",
    "#Create training and validation DMatrix\n",
    "xgtrain = xgb.DMatrix(train[offset:, :], label=labels[offset:])\n",
    "xgval = xgb.DMatrix(train[:offset, :], label=labels[:offset])\n",
    "\n",
    "evallist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, num_rounds, evallist, early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_train = train[::-1,:]\n",
    "r_labels = labels[::-1]\n",
    "#Create training and validation DMatrix for remaining data\n",
    "r_xgtrain = xgb.DMatrix(r_train[offset:, :], label=r_labels[offset:])\n",
    "r_xgval = xgb.DMatrix(r_train[:offset, :], label=r_labels[:offset])\n",
    "\n",
    "evallist = [(r_xgtrain, 'r_train'), (r_xgval, 'r_val')]\n",
    "r_model = xgb.train(plst, r_xgtrain, num_rounds, evallist, early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "r_preds = r_model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "avg_preds = ((preds)*0.6 + (r_preds)*0.4)\n",
    "\n",
    "preds = pd.DataFrame({\"QuoteNumber\": test_ind, \"QuoteConversion_Flag\": preds})\n",
    "preds = preds.set_index('QuoteNumber')\n",
    "\n",
    "r_preds = pd.DataFrame({\"QuoteNumber\": test_ind, \"QuoteConversion_Flag\": r_preds})\n",
    "r_preds = r_preds.set_index('QuoteNumber')\n",
    "\n",
    "avg_preds = pd.DataFrame({\"QuoteNumber\": test_ind, \"QuoteConversion_Flag\": avg_preds})\n",
    "avg_preds = avg_preds.set_index('QuoteNumber')\n",
    "avg_preds.to_csv('data/output/xgboost_withDate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "1. XGBoost model\n",
    "2. Multi-threaded process\n",
    "\n",
    "## What's next\n",
    "\n",
    "1. Cross validation\n",
    "2. Handling missing values\n",
    "3. Grid search hyper-parameter\n",
    "4. Stacked xgboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
